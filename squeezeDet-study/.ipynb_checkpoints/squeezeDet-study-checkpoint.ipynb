{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is my note of study SqueezeDet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "\n",
    "from config import *\n",
    "from dataset import pascal_voc, kitti\n",
    "from utils.util import sparse_to_dense, bgr_to_rgb, bbox_transform\n",
    "from nets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine if train_dir is exist, if it is exist will delete it.\n",
    "## Then make a file for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None): \n",
    "    if tf.gfile.Exists(FLAGS.train_dir): #\n",
    "        tf.gfile.DeleteRecursively(FLAGS.train_dir)\n",
    "\n",
    "    tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=orange > <font face=\"purisa\" size=8 color='0000ff'>\n",
    " Extended learning\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "<table><tr><td bgcolor=white > <font face=\"sawasdee\" size=8 color='0000ff'>\n",
    " tf.gfile.DeleeRecursively & tf.gfile.MakeDirs\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<font face=\"微软雅黑\" size=6 color='0000ff'> 1. Let us know \"tf.gfile\"<br> </font>\n",
    "<br>\n",
    " \n",
    "<font face=\"微软雅黑\" size=4 color='000000'>\n",
    "The main roles of the tf.gfile module are:\n",
    "    <br>\n",
    "    *:To provide an API that is close to Python's file objects <br>\n",
    "    *:To provide an implementation based on TensorFlow's C++ filesystem API\n",
    "<br> \n",
    "</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "<font face=\"微软雅黑\" size=6 color='0000ff'>2. Let us know \"tf.gfile.DeleeRecursively\"  <br></font>\n",
    "<br>\n",
    "\n",
    "<font face=\"微软雅黑\" size=4 color='000000'>\n",
    "tf.gfile.DeleteRecursively(dirname)\n",
    "\n",
    "Defined in tensorflow/python/lib/io/file_io.py.\n",
    "\n",
    "Deletes everything under dirname recursively.\n",
    "Args:\n",
    "\n",
    "    *dirname: string, a path to a directory\n",
    "\n",
    "Raises:\n",
    "\n",
    "    *errors.OpError: If the operation fails.\n",
    " </font>\n",
    "<br>   \n",
    "    \n",
    "    \n",
    "<font face=\"微软雅黑\" size=6 color='0000ff'> 3. Let us know \"tf.gfile.MakeDirs\" </font><br>  \n",
    "\n",
    "<font face=\"微软雅黑\" size=4 color='#000000'>    \n",
    "tf.gfile.MakeDirs(dirname)\n",
    "\n",
    "Defined in tensorflow/python/lib/io/file_io.py.\n",
    "\n",
    "Creates a directory and all parent/intermediate directories.\n",
    "\n",
    "It succeeds if dirname already exists and is writable.\n",
    "Args:\n",
    "\n",
    "    *dirname: string, name of the directory to be created\n",
    "\n",
    "Raises:\n",
    "\n",
    "    *errors.OpError: If the operation fails.\n",
    "\n",
    " </font>\n",
    "<br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting 'CUDA_VISIBLE_DEVICES' to use  witch GPU for trianing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  \"\"\"Train SqueezeDet model\"\"\"\n",
    "  assert FLAGS.dataset == 'KITTI', \\\n",
    "      'Currently only support KITTI dataset'\n",
    "\n",
    "  os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=orange > <font face=\"purisa\" size=8 color='0000ff'>\n",
    " Extended learning\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "<table><tr><td bgcolor=white > <font face=\"sawasdee\" size=8 color='0000ff'>\n",
    " assert\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "## Python's assert statement helps you find bugs more quickly and with less pain. This note has some suggestions on good ways to use it. \n",
    "\n",
    "## For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Currently only support KITTI dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-4adefd95b315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'KITTI'\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0;34m'Currently only support KITTI dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Currently only support KITTI dataset"
     ]
    }
   ],
   "source": [
    "dataset = 'dd'\n",
    "assert dataset == 'KITTI', \\\n",
    "      'Currently only support KITTI dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define operations and tensors use tf.Graph().as_default()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=orange > <font face=\"purisa\" size=8 color='0000ff'>\n",
    " Extended learning\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "<table><tr><td bgcolor=white > <font face=\"sawasdee\" size=8 color='0000ff'>\n",
    " with\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "有一些任务，可能事先需要设置，事后做清理工作。对于这种场景，Python的with语句提供了一种非常方便的处理方式。一个很好的例子是文件处理，你需要获取一个文件句柄，从文件中读取数据，然后关闭文件句柄。\n",
    "如果不用with语句，代码如下：\n",
    "\n",
    "file = open(\"/tmp/foo.txt\")\n",
    "data = file.read()\n",
    "file.close()\n",
    "\n",
    "这里有两个问题。一是可能忘记关闭文件句柄；二是文件读取数据发生异常，没有进行任何处理。下面是处理异常的加强版本：\n",
    "\n",
    "file = open(\"/tmp/foo.txt\")\n",
    "try:\n",
    "    data = file.read()\n",
    "finally:\n",
    "    file.close()\n",
    "\n",
    "虽然这段代码运行良好，但是太冗长了。这时候就是with一展身手的时候了。除了有更优雅的语法，with还可以很好的处理上下文环境产生的异常。下面是with版本的代码：\n",
    "\n",
    "with open(\"/tmp/foo.txt\") as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the parameters to tune, such as image width, image height, batch size, weight decay...\n",
    "## Specify the Layer imformation of SqueezeDet model\n",
    "## kitti_squeezeDet_config() from ./scr/config/kitti_squeezeDet_config.py\n",
    "## SqueezeDet() from ./scr/nets/SqueezeDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot find fire10/squeeze1x1 in the pretrained model. Use randomly initialized parameters\n",
      "Cannot find fire10/expand1x1 in the pretrained model. Use randomly initialized parameters\n",
      "Cannot find fire10/expand3x3 in the pretrained model. Use randomly initialized parameters\n",
      "Cannot find fire11/squeeze1x1 in the pretrained model. Use randomly initialized parameters\n",
      "Cannot find fire11/expand1x1 in the pretrained model. Use randomly initialized parameters\n",
      "Cannot find fire11/expand3x3 in the pretrained model. Use randomly initialized parameters\n",
      "Cannot find conv12 in the pretrained model. Use randomly initialized parameters\n",
      "INFO:tensorflow:Summary name mean iou is illegal; using mean_iou instead.\n"
     ]
    }
   ],
   "source": [
    "    ## elif FLAGS.net == 'squeezeDet':\n",
    "mc = kitti_squeezeDet_config()\n",
    "mc.IS_TRAINING = True\n",
    "mc.PRETRAINED_MODEL_PATH = '../squeezeDet-master/data/SqueezeNet/squeezenet_v1.1.pkl'#FLAGS.pretrained_model_path\n",
    "model = SqueezeDet(mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "imdb = kitti(FLAGS.image_set, FLAGS.data_path, mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=orange > <font face=\"purisa\" size=8 color='0000ff'>\n",
    " Extended learning\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "<table><tr><td bgcolor=white > <font face=\"sawasdee\" size=6 color='0000ff'>\n",
    "Read the names and parameters of layers from .ckpt\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "## Sometimes we have a .cpkt file, and we want to get the names and parameters of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../squeezeDet-master/data/model_checkpoints/squeezeDet/model.ckpt-87000\n",
      "tensor_name fire4/expand1x1/biases\n",
      "tensor_name fire9/expand1x1/kernels/Momentum\n",
      "tensor_name fire6/expand1x1/biases\n",
      "tensor_name fire4/expand3x3/kernels\n",
      "tensor_name fire11/expand3x3/kernels/Momentum\n",
      "tensor_name fire6/expand3x3/biases/Momentum\n",
      "tensor_name fire2/squeeze1x1/biases\n",
      "tensor_name fire2/squeeze1x1/kernels\n",
      "tensor_name fire11/expand3x3/kernels\n",
      "tensor_name fire5/expand1x1/kernels/Momentum\n",
      "tensor_name fire10/expand3x3/biases\n",
      "tensor_name fire7/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire4/squeeze1x1/biases\n",
      "tensor_name fire2/expand1x1/kernels/Momentum\n",
      "tensor_name fire8/squeeze1x1/biases\n",
      "tensor_name fire6/expand1x1/kernels\n",
      "tensor_name fire4/expand1x1/kernels\n",
      "tensor_name fire11/expand3x3/biases/Momentum\n",
      "tensor_name fire10/expand1x1/kernels\n",
      "tensor_name fire4/squeeze1x1/kernels\n",
      "tensor_name fire4/expand3x3/kernels/Momentum\n",
      "tensor_name fire4/squeeze1x1/biases/Momentum\n",
      "tensor_name fire11/expand1x1/kernels\n",
      "tensor_name fire6/expand3x3/kernels/Momentum\n",
      "tensor_name fire7/expand1x1/kernels/Momentum\n",
      "tensor_name fire10/expand1x1/kernels/Momentum\n",
      "tensor_name fire2/squeeze1x1/biases/Momentum\n",
      "tensor_name fire2/expand1x1/biases/Momentum\n",
      "tensor_name fire2/expand3x3/kernels\n",
      "tensor_name fire2/expand3x3/biases/Momentum\n",
      "tensor_name fire4/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire8/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire8/expand3x3/kernels\n",
      "tensor_name fire3/expand1x1/kernels/Momentum\n",
      "tensor_name fire2/expand1x1/biases\n",
      "tensor_name fire5/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire3/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire10/expand1x1/biases/Momentum\n",
      "tensor_name fire8/squeeze1x1/kernels\n",
      "tensor_name fire11/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire8/expand3x3/biases/Momentum\n",
      "tensor_name fire9/expand1x1/kernels\n",
      "tensor_name fire3/expand3x3/kernels\n",
      "tensor_name conv12/kernels\n",
      "tensor_name fire8/expand1x1/biases/Momentum\n",
      "tensor_name fire9/expand1x1/biases\n",
      "tensor_name fire7/squeeze1x1/kernels\n",
      "tensor_name fire11/squeeze1x1/biases\n",
      "tensor_name fire11/expand3x3/biases\n",
      "tensor_name fire3/expand3x3/biases\n",
      "tensor_name fire7/expand3x3/kernels\n",
      "tensor_name fire6/expand1x1/biases/Momentum\n",
      "tensor_name fire7/expand1x1/biases\n",
      "tensor_name fire6/expand3x3/kernels\n",
      "tensor_name fire2/expand3x3/biases\n",
      "tensor_name fire11/expand1x1/biases/Momentum\n",
      "tensor_name fire10/expand3x3/kernels/Momentum\n",
      "tensor_name fire6/squeeze1x1/biases/Momentum\n",
      "tensor_name fire2/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire5/squeeze1x1/biases\n",
      "tensor_name fire5/expand1x1/biases\n",
      "tensor_name fire8/expand1x1/kernels/Momentum\n",
      "tensor_name fire7/expand1x1/kernels\n",
      "tensor_name conv12/biases\n",
      "tensor_name fire3/squeeze1x1/kernels\n",
      "tensor_name fire5/expand3x3/biases\n",
      "tensor_name fire10/squeeze1x1/kernels\n",
      "tensor_name fire4/expand3x3/biases/Momentum\n",
      "tensor_name fire8/expand1x1/biases\n",
      "tensor_name fire8/expand3x3/kernels/Momentum\n",
      "tensor_name fire10/expand1x1/biases\n",
      "tensor_name fire9/expand3x3/kernels\n",
      "tensor_name fire7/expand1x1/biases/Momentum\n",
      "tensor_name fire8/expand3x3/biases\n",
      "tensor_name fire3/expand1x1/kernels\n",
      "tensor_name fire4/expand1x1/biases/Momentum\n",
      "tensor_name fire10/squeeze1x1/biases\n",
      "tensor_name fire6/expand3x3/biases\n",
      "tensor_name fire5/expand3x3/biases/Momentum\n",
      "tensor_name fire9/squeeze1x1/kernels\n",
      "tensor_name fire7/expand3x3/biases/Momentum\n",
      "tensor_name fire7/squeeze1x1/biases\n",
      "tensor_name fire3/expand3x3/kernels/Momentum\n",
      "tensor_name fire4/expand3x3/biases\n",
      "tensor_name fire8/expand1x1/kernels\n",
      "tensor_name fire9/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire9/expand3x3/biases/Momentum\n",
      "tensor_name fire10/expand3x3/biases/Momentum\n",
      "tensor_name conv1/biases\n",
      "tensor_name conv12/biases/Momentum\n",
      "tensor_name fire5/expand3x3/kernels\n",
      "tensor_name fire2/expand3x3/kernels/Momentum\n",
      "tensor_name fire7/squeeze1x1/biases/Momentum\n",
      "tensor_name conv1/kernels\n",
      "tensor_name fire9/expand1x1/biases/Momentum\n",
      "tensor_name fire2/expand1x1/kernels\n",
      "tensor_name fire3/expand1x1/biases/Momentum\n",
      "tensor_name fire9/expand3x3/kernels/Momentum\n",
      "tensor_name global_step\n",
      "tensor_name fire10/expand3x3/kernels\n",
      "tensor_name fire3/squeeze1x1/biases\n",
      "tensor_name fire6/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire11/expand1x1/kernels/Momentum\n",
      "tensor_name fire8/squeeze1x1/biases/Momentum\n",
      "tensor_name fire5/squeeze1x1/kernels\n",
      "tensor_name fire3/expand3x3/biases/Momentum\n",
      "tensor_name fire6/expand1x1/kernels/Momentum\n",
      "tensor_name fire4/expand1x1/kernels/Momentum\n",
      "tensor_name fire5/expand3x3/kernels/Momentum\n",
      "tensor_name fire7/expand3x3/biases\n",
      "tensor_name iou\n",
      "tensor_name fire7/expand3x3/kernels/Momentum\n",
      "tensor_name fire6/squeeze1x1/biases\n",
      "tensor_name fire3/expand1x1/biases\n",
      "tensor_name fire5/squeeze1x1/biases/Momentum\n",
      "tensor_name conv12/kernels/Momentum\n",
      "tensor_name fire9/squeeze1x1/biases\n",
      "tensor_name fire6/squeeze1x1/kernels\n",
      "tensor_name fire10/squeeze1x1/biases/Momentum\n",
      "tensor_name fire5/expand1x1/kernels\n",
      "tensor_name fire9/squeeze1x1/biases/Momentum\n",
      "tensor_name fire11/squeeze1x1/biases/Momentum\n",
      "tensor_name fire9/expand3x3/biases\n",
      "tensor_name fire3/squeeze1x1/biases/Momentum\n",
      "tensor_name fire11/expand1x1/biases\n",
      "tensor_name fire11/squeeze1x1/kernels\n",
      "tensor_name fire10/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire5/expand1x1/biases/Momentum\n",
      "[ -9.12857614e-03  -2.08038148e-02   2.65010018e-02 ...,  -2.69910342e-05\n",
      "   2.42647293e-05  -2.81593257e-05] (4463409,) 87001.0 -1.47793996334 0.0182695371489\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "checkpoint_path=\"../squeezeDet-master/data/model_checkpoints/squeezeDet/model.ckpt-87000\"\n",
    "# print(path.getcwdu())\n",
    "print(checkpoint_path)\n",
    "#read data from checkpoint file\n",
    "reader=pywrap_tensorflow.NewCheckpointReader(checkpoint_path)\n",
    "var_to_shape_map=reader.get_variable_to_shape_map()\n",
    "data_print=np.array([])\n",
    "for key in var_to_shape_map:\n",
    "    print('tensor_name',key)\n",
    "    ckpt_data=np.array(reader.get_tensor(key))#cast list to np arrary\n",
    "    ckpt_data=ckpt_data.flatten()#flatten list\n",
    "    data_print=np.append(data_print,ckpt_data,axis=0)\n",
    " \n",
    " \n",
    "print(data_print,data_print.shape,np.max(data_print),np.min(data_print),np.mean(data_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 32, 128)\n",
      "[[ 0.00030935 -0.04224271 -0.00912083]\n",
      " [ 0.01631369 -0.04829923 -0.02703618]\n",
      " [ 0.05631071  0.01756266  0.00989039]]\n"
     ]
    }
   ],
   "source": [
    "parameter_fire4 = reader.get_tensor(\"fire4/expand3x3/kernels\")\n",
    "print(parameter_fire4.shape)\n",
    "print(parameter_fire4[:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor number: 9\n",
      "Classes number: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Anchor number:\", mc.ANCHOR_PER_GRID)\n",
    "print(\"Classes number:\", mc.CLASSES)\n",
    "num_output = mc.ANCHOR_PER_GRID * (mc.CLASSES + 1 + 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
