{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is my note of study SqueezeDet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "\n",
    "from config import *\n",
    "from dataset import pascal_voc, kitti\n",
    "from utils.util import sparse_to_dense, bgr_to_rgb, bbox_transform\n",
    "from nets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine if train_dir is exist, if it is exist will delete it.\n",
    "## Then make a file for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None): \n",
    "    if tf.gfile.Exists(FLAGS.train_dir): #\n",
    "        tf.gfile.DeleteRecursively(FLAGS.train_dir)\n",
    "\n",
    "    tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=orange > <font face=\"purisa\" size=8 color='0000ff'>\n",
    " Extended learning\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "<table><tr><td bgcolor=white > <font face=\"sawasdee\" size=8 color='0000ff'>\n",
    " tf.gfile.DeleeRecursively & tf.gfile.MakeDirs\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<font face=\"微软雅黑\" size=6 color='0000ff'> 1. Let us know \"tf.gfile\"<br> </font>\n",
    "<br>\n",
    " \n",
    "<font face=\"微软雅黑\" size=4 color='000000'>\n",
    "The main roles of the tf.gfile module are:\n",
    "    <br>\n",
    "    *:To provide an API that is close to Python's file objects <br>\n",
    "    *:To provide an implementation based on TensorFlow's C++ filesystem API\n",
    "<br> \n",
    "</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "<font face=\"微软雅黑\" size=6 color='0000ff'>2. Let us know \"tf.gfile.DeleeRecursively\"  <br></font>\n",
    "<br>\n",
    "\n",
    "<font face=\"微软雅黑\" size=4 color='000000'>\n",
    "tf.gfile.DeleteRecursively(dirname)\n",
    "\n",
    "Defined in tensorflow/python/lib/io/file_io.py.\n",
    "\n",
    "Deletes everything under dirname recursively.\n",
    "Args:\n",
    "\n",
    "    *dirname: string, a path to a directory\n",
    "\n",
    "Raises:\n",
    "\n",
    "    *errors.OpError: If the operation fails.\n",
    " </font>\n",
    "<br>   \n",
    "    \n",
    "    \n",
    "<font face=\"微软雅黑\" size=6 color='0000ff'> 3. Let us know \"tf.gfile.MakeDirs\" </font><br>  \n",
    "\n",
    "<font face=\"微软雅黑\" size=4 color='#000000'>    \n",
    "tf.gfile.MakeDirs(dirname)\n",
    "\n",
    "Defined in tensorflow/python/lib/io/file_io.py.\n",
    "\n",
    "Creates a directory and all parent/intermediate directories.\n",
    "\n",
    "It succeeds if dirname already exists and is writable.\n",
    "Args:\n",
    "\n",
    "    *dirname: string, name of the directory to be created\n",
    "\n",
    "Raises:\n",
    "\n",
    "    *errors.OpError: If the operation fails.\n",
    "\n",
    " </font>\n",
    "<br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting 'CUDA_VISIBLE_DEVICES' to use  witch GPU for trianing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  \"\"\"Train SqueezeDet model\"\"\"\n",
    "  assert FLAGS.dataset == 'KITTI', \\\n",
    "      'Currently only support KITTI dataset'\n",
    "\n",
    "  os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=orange > <font face=\"purisa\" size=8 color='0000ff'>\n",
    " Extended learning\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "<table><tr><td bgcolor=white > <font face=\"sawasdee\" size=8 color='0000ff'>\n",
    " assert\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "## Python's assert statement helps you find bugs more quickly and with less pain. This note has some suggestions on good ways to use it. \n",
    "\n",
    "## For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Currently only support KITTI dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-4adefd95b315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'KITTI'\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0;34m'Currently only support KITTI dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Currently only support KITTI dataset"
     ]
    }
   ],
   "source": [
    "dataset = 'dd'\n",
    "assert dataset == 'KITTI', \\\n",
    "      'Currently only support KITTI dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define operations and tensors use tf.Graph().as_default()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=orange > <font face=\"purisa\" size=8 color='0000ff'>\n",
    " Extended learning\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "<table><tr><td bgcolor=white > <font face=\"sawasdee\" size=8 color='0000ff'>\n",
    " with\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "有一些任务，可能事先需要设置，事后做清理工作。对于这种场景，Python的with语句提供了一种非常方便的处理方式。一个很好的例子是文件处理，你需要获取一个文件句柄，从文件中读取数据，然后关闭文件句柄。\n",
    "如果不用with语句，代码如下：\n",
    "\n",
    "file = open(\"/tmp/foo.txt\")\n",
    "data = file.read()\n",
    "file.close()\n",
    "\n",
    "这里有两个问题。一是可能忘记关闭文件句柄；二是文件读取数据发生异常，没有进行任何处理。下面是处理异常的加强版本：\n",
    "\n",
    "file = open(\"/tmp/foo.txt\")\n",
    "try:\n",
    "    data = file.read()\n",
    "finally:\n",
    "    file.close()\n",
    "\n",
    "虽然这段代码运行良好，但是太冗长了。这时候就是with一展身手的时候了。除了有更优雅的语法，with还可以很好的处理上下文环境产生的异常。下面是with版本的代码：\n",
    "\n",
    "with open(\"/tmp/foo.txt\") as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the parameters to tune, such as image width, image height, batch size, weight decay...\n",
    "## Specify the Layer imformation of SqueezeDet model\n",
    "## kitti_squeezeDet_config() from ./scr/config/kitti_squeezeDet_config.py\n",
    "\n",
    "### def kitti_squeezeDet_config():\n",
    "###  \"\"\"Specify the parameters to tune below.\"\"\"\n",
    "###  mc                       = base_model_config('KITTI')\n",
    "\n",
    "###  mc.IMAGE_WIDTH           = 1248\n",
    "###  mc.IMAGE_HEIGHT          = 384\n",
    "###  mc.BATCH_SIZE            = 20\n",
    "\n",
    "###  mc.WEIGHT_DECAY          = 0.0001\n",
    "###  mc.LEARNING_RATE         = 0.01\n",
    "###  mc.DECAY_STEPS           = 10000\n",
    "###  mc.MAX_GRAD_NORM         = 1.0\n",
    "###  mc.MOMENTUM              = 0.9\n",
    "###  mc.LR_DECAY_FACTOR       = 0.5\n",
    "\n",
    "###   mc.LOSS_COEF_BBOX        = 5.0\n",
    "###   mc.LOSS_COEF_CONF_POS    = 75.0\n",
    "###   mc### .LOSS_COEF_CONF_NEG    = 100.0\n",
    "###   mc.LOS### S_COEF_CLASS       = 1.0\n",
    "\n",
    "###   mc.PLOT_PROB_THRESH      = 0.4\n",
    "###   mc.NMS_THRESH            = 0.4\n",
    "###   mc.PROB_THRESH           = 0.005\n",
    "###   mc.TOP_N_DETECTION       = 64\n",
    "\n",
    "###   mc.DATA_AUGMENTATION     = True\n",
    "###   mc.DRIFT_X               = 150\n",
    "###   mc.DRIFT_Y               = 100\n",
    "###   mc.EXCLUDE_HARD_EXAMPLES = False\n",
    "\n",
    "###   mc.ANCHOR_BOX            = set_anchors(mc)\n",
    "###   mc.ANCHORS               = len(mc.ANCHOR_BOX)\n",
    "###   mc.ANCHOR_PER_GRID       = 9\n",
    "\n",
    "###   return mc\n",
    "\n",
    "# classes and classes names form base_mode_config('KITTI')\n",
    "\n",
    "## SqueezeDet() from ./scr/nets/SqueezeDet\n",
    "\n",
    "###   self.caffemodel_weight = joblib.load(mc.PRETRAINED_MODEL_PATH)\n",
    "\n",
    "###    conv1 = self._conv_layer(\n",
    "###        'conv1', self.image_input, filters=64, size=3, stride=2,\n",
    "###        padding='SAME', freeze=True)\n",
    "###    pool1 = self._pooling_layer(\n",
    "###        'pool1', conv1, size=3, stride=2, padding='SAME')\n",
    "\n",
    "###    fire2 = self._fire_layer(\n",
    "###        'fire2', pool1, s1x1=16, e1x1=64, e3x3=64, freeze=False)\n",
    "###    fire3 = self._fire_layer(\n",
    "###        'fire3', fire2, s1x1=16, e1x1=64, e3x3=64, freeze=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NMS_THRESH': 0.4, 'LOSS_COEF_CONF_NEG': 100.0, 'KEEP_PROB': 0.5, 'IMAGE_WIDTH': 1248, 'NUM_THREAD': 4, 'LOSS_COEF_CONF_POS': 75.0, 'GRID_POOL_HEIGHT': 7, 'PLOT_PROB_THRESH': 0.4, 'TOP_N_DETECTION': 64, 'LOSS_COEF_CLASS': 1.0, 'BGR_MEANS': array([[[ 103.939,  116.779,  123.68 ]]]), 'PROB_THRESH': 0.005, 'BATCH_SIZE': 20, 'DATASET': 'KITTI', 'DEBUG_MODE': False, 'MAX_GRAD_NORM': 1.0, 'EXP_THRESH': 1.0, 'DRIFT_X': 150, 'LEARNING_RATE': 0.01, 'CLASS_NAMES': ['car', 'pedestrian', 'cyclist'], 'LEAKY_COEF': 0.1, 'EXCLUDE_HARD_EXAMPLES': False, 'QUEUE_CAPACITY': 100, 'DATA_AUGMENTATION': True, 'GRID_POOL_WIDTH': 7, 'PRETRAINED_MODEL_PATH': '', 'CLASSES': 3, 'IS_TRAINING': False, 'ANCHOR_BOX': array([[   15.79746835,    15.36      ,    36.        ,    37.        ],\n",
      "       [   15.79746835,    15.36      ,   366.        ,   174.        ],\n",
      "       [   15.79746835,    15.36      ,   115.        ,    59.        ],\n",
      "       ..., \n",
      "       [ 1232.20253165,   368.64      ,   224.        ,   108.        ],\n",
      "       [ 1232.20253165,   368.64      ,    78.        ,   170.        ],\n",
      "       [ 1232.20253165,   368.64      ,    72.        ,    43.        ]]), 'BATCH_NORM_EPSILON': 1e-05, 'LOSS_COEF_BBOX': 5.0, 'LR_DECAY_FACTOR': 0.5, 'ANCHORS': 16848, 'ANCHOR_PER_GRID': 9, 'LOSS_COEF_CONF': 1.0, 'EPSILON': 1e-16, 'LOAD_PRETRAINED_MODEL': True, 'DECAY_STEPS': 10000, 'DRIFT_Y': 100, 'IMAGE_HEIGHT': 384, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001}\n",
      "Cannot find fire10/squeeze1x1 in the pretrained model. Use randomly initialized parameters\n",
      "Cannot find fire10/expand1x1 in the pretrained model. Use randomly initialized parameters\n",
      "Cannot find fire10/expand3x3 in the pretrained model. Use randomly initialized parameters\n",
      "Cannot find fire11/squeeze1x1 in the pretrained model. Use randomly initialized parameters\n",
      "Cannot find fire11/expand1x1 in the pretrained model. Use randomly initialized parameters\n",
      "Cannot find fire11/expand3x3 in the pretrained model. Use randomly initialized parameters\n",
      "Cannot find conv12 in the pretrained model. Use randomly initialized parameters\n",
      "INFO:tensorflow:Summary name mean iou is illegal; using mean_iou instead.\n"
     ]
    }
   ],
   "source": [
    "    ## elif FLAGS.net == 'squeezeDet':\n",
    "\n",
    "mc = kitti_squeezeDet_config()\n",
    "print(mc)\n",
    "mc.IS_TRAINING = True\n",
    "mc.PRETRAINED_MODEL_PATH = '../squeezeDet-master/data/SqueezeNet/squeezenet_v1.1.pkl'#FLAGS.pretrained_model_path\n",
    "model = SqueezeDet(mc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "imdb = kitti(FLAGS.image_set, FLAGS.data_path, mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=orange > <font face=\"purisa\" size=8 color='0000ff'>\n",
    " Extended learning\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "<table><tr><td bgcolor=white > <font face=\"sawasdee\" size=6 color='0000ff'>\n",
    "Read the names and parameters of layers from .ckpt\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "## Sometimes we have a .cpkt file, and we want to get the names and parameters of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../squeezeDet-master/data/model_checkpoints/squeezeDet/model.ckpt-87000\n",
      "tensor_name fire4/expand1x1/biases\n",
      "tensor_name fire9/expand1x1/kernels/Momentum\n",
      "tensor_name fire6/expand1x1/biases\n",
      "tensor_name fire4/expand3x3/kernels\n",
      "tensor_name fire11/expand3x3/kernels/Momentum\n",
      "tensor_name fire6/expand3x3/biases/Momentum\n",
      "tensor_name fire2/squeeze1x1/biases\n",
      "tensor_name fire2/squeeze1x1/kernels\n",
      "tensor_name fire11/expand3x3/kernels\n",
      "tensor_name fire5/expand1x1/kernels/Momentum\n",
      "tensor_name fire10/expand3x3/biases\n",
      "tensor_name fire7/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire4/squeeze1x1/biases\n",
      "tensor_name fire2/expand1x1/kernels/Momentum\n",
      "tensor_name fire8/squeeze1x1/biases\n",
      "tensor_name fire6/expand1x1/kernels\n",
      "tensor_name fire4/expand1x1/kernels\n",
      "tensor_name fire11/expand3x3/biases/Momentum\n",
      "tensor_name fire10/expand1x1/kernels\n",
      "tensor_name fire4/squeeze1x1/kernels\n",
      "tensor_name fire4/expand3x3/kernels/Momentum\n",
      "tensor_name fire4/squeeze1x1/biases/Momentum\n",
      "tensor_name fire11/expand1x1/kernels\n",
      "tensor_name fire6/expand3x3/kernels/Momentum\n",
      "tensor_name fire7/expand1x1/kernels/Momentum\n",
      "tensor_name fire10/expand1x1/kernels/Momentum\n",
      "tensor_name fire2/squeeze1x1/biases/Momentum\n",
      "tensor_name fire2/expand1x1/biases/Momentum\n",
      "tensor_name fire2/expand3x3/kernels\n",
      "tensor_name fire2/expand3x3/biases/Momentum\n",
      "tensor_name fire4/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire8/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire8/expand3x3/kernels\n",
      "tensor_name fire3/expand1x1/kernels/Momentum\n",
      "tensor_name fire2/expand1x1/biases\n",
      "tensor_name fire5/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire3/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire10/expand1x1/biases/Momentum\n",
      "tensor_name fire8/squeeze1x1/kernels\n",
      "tensor_name fire11/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire8/expand3x3/biases/Momentum\n",
      "tensor_name fire9/expand1x1/kernels\n",
      "tensor_name fire3/expand3x3/kernels\n",
      "tensor_name conv12/kernels\n",
      "tensor_name fire8/expand1x1/biases/Momentum\n",
      "tensor_name fire9/expand1x1/biases\n",
      "tensor_name fire7/squeeze1x1/kernels\n",
      "tensor_name fire11/squeeze1x1/biases\n",
      "tensor_name fire11/expand3x3/biases\n",
      "tensor_name fire3/expand3x3/biases\n",
      "tensor_name fire7/expand3x3/kernels\n",
      "tensor_name fire6/expand1x1/biases/Momentum\n",
      "tensor_name fire7/expand1x1/biases\n",
      "tensor_name fire6/expand3x3/kernels\n",
      "tensor_name fire2/expand3x3/biases\n",
      "tensor_name fire11/expand1x1/biases/Momentum\n",
      "tensor_name fire10/expand3x3/kernels/Momentum\n",
      "tensor_name fire6/squeeze1x1/biases/Momentum\n",
      "tensor_name fire2/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire5/squeeze1x1/biases\n",
      "tensor_name fire5/expand1x1/biases\n",
      "tensor_name fire8/expand1x1/kernels/Momentum\n",
      "tensor_name fire7/expand1x1/kernels\n",
      "tensor_name conv12/biases\n",
      "tensor_name fire3/squeeze1x1/kernels\n",
      "tensor_name fire5/expand3x3/biases\n",
      "tensor_name fire10/squeeze1x1/kernels\n",
      "tensor_name fire4/expand3x3/biases/Momentum\n",
      "tensor_name fire8/expand1x1/biases\n",
      "tensor_name fire8/expand3x3/kernels/Momentum\n",
      "tensor_name fire10/expand1x1/biases\n",
      "tensor_name fire9/expand3x3/kernels\n",
      "tensor_name fire7/expand1x1/biases/Momentum\n",
      "tensor_name fire8/expand3x3/biases\n",
      "tensor_name fire3/expand1x1/kernels\n",
      "tensor_name fire4/expand1x1/biases/Momentum\n",
      "tensor_name fire10/squeeze1x1/biases\n",
      "tensor_name fire6/expand3x3/biases\n",
      "tensor_name fire5/expand3x3/biases/Momentum\n",
      "tensor_name fire9/squeeze1x1/kernels\n",
      "tensor_name fire7/expand3x3/biases/Momentum\n",
      "tensor_name fire7/squeeze1x1/biases\n",
      "tensor_name fire3/expand3x3/kernels/Momentum\n",
      "tensor_name fire4/expand3x3/biases\n",
      "tensor_name fire8/expand1x1/kernels\n",
      "tensor_name fire9/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire9/expand3x3/biases/Momentum\n",
      "tensor_name fire10/expand3x3/biases/Momentum\n",
      "tensor_name conv1/biases\n",
      "tensor_name conv12/biases/Momentum\n",
      "tensor_name fire5/expand3x3/kernels\n",
      "tensor_name fire2/expand3x3/kernels/Momentum\n",
      "tensor_name fire7/squeeze1x1/biases/Momentum\n",
      "tensor_name conv1/kernels\n",
      "tensor_name fire9/expand1x1/biases/Momentum\n",
      "tensor_name fire2/expand1x1/kernels\n",
      "tensor_name fire3/expand1x1/biases/Momentum\n",
      "tensor_name fire9/expand3x3/kernels/Momentum\n",
      "tensor_name global_step\n",
      "tensor_name fire10/expand3x3/kernels\n",
      "tensor_name fire3/squeeze1x1/biases\n",
      "tensor_name fire6/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire11/expand1x1/kernels/Momentum\n",
      "tensor_name fire8/squeeze1x1/biases/Momentum\n",
      "tensor_name fire5/squeeze1x1/kernels\n",
      "tensor_name fire3/expand3x3/biases/Momentum\n",
      "tensor_name fire6/expand1x1/kernels/Momentum\n",
      "tensor_name fire4/expand1x1/kernels/Momentum\n",
      "tensor_name fire5/expand3x3/kernels/Momentum\n",
      "tensor_name fire7/expand3x3/biases\n",
      "tensor_name iou\n",
      "tensor_name fire7/expand3x3/kernels/Momentum\n",
      "tensor_name fire6/squeeze1x1/biases\n",
      "tensor_name fire3/expand1x1/biases\n",
      "tensor_name fire5/squeeze1x1/biases/Momentum\n",
      "tensor_name conv12/kernels/Momentum\n",
      "tensor_name fire9/squeeze1x1/biases\n",
      "tensor_name fire6/squeeze1x1/kernels\n",
      "tensor_name fire10/squeeze1x1/biases/Momentum\n",
      "tensor_name fire5/expand1x1/kernels\n",
      "tensor_name fire9/squeeze1x1/biases/Momentum\n",
      "tensor_name fire11/squeeze1x1/biases/Momentum\n",
      "tensor_name fire9/expand3x3/biases\n",
      "tensor_name fire3/squeeze1x1/biases/Momentum\n",
      "tensor_name fire11/expand1x1/biases\n",
      "tensor_name fire11/squeeze1x1/kernels\n",
      "tensor_name fire10/squeeze1x1/kernels/Momentum\n",
      "tensor_name fire5/expand1x1/biases/Momentum\n",
      "[ -9.12857614e-03  -2.08038148e-02   2.65010018e-02 ...,  -2.69910342e-05\n",
      "   2.42647293e-05  -2.81593257e-05] (4463409,) 87001.0 -1.47793996334 0.0182695371489\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "checkpoint_path=\"../squeezeDet-master/data/model_checkpoints/squeezeDet/model.ckpt-87000\"\n",
    "# print(path.getcwdu())\n",
    "print(checkpoint_path)\n",
    "#read data from checkpoint file\n",
    "reader=pywrap_tensorflow.NewCheckpointReader(checkpoint_path)\n",
    "var_to_shape_map=reader.get_variable_to_shape_map()\n",
    "data_print=np.array([])\n",
    "for key in var_to_shape_map:\n",
    "    print('tensor_name',key)\n",
    "    ckpt_data=np.array(reader.get_tensor(key))#cast list to np arrary\n",
    "    ckpt_data=ckpt_data.flatten()#flatten list\n",
    "    data_print=np.append(data_print,ckpt_data,axis=0)\n",
    " \n",
    " \n",
    "print(data_print,data_print.shape,np.max(data_print),np.min(data_print),np.mean(data_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72,)\n",
      "[  2.67206039e-02   3.06304753e-01  -3.33028406e-01   6.52096748e-01\n",
      "  -2.89292663e-01  -3.62792015e-01   1.01041019e+00  -7.65033066e-01\n",
      "  -2.45314330e-01   6.69764757e-01  -6.41299248e-01  -2.83657033e-02\n",
      "  -3.77765059e-01   5.24263263e-01  -1.46511480e-01   1.41501911e-02\n",
      "  -1.65120184e-01   1.50972545e-01   7.24290848e-01  -4.63925958e-01\n",
      "  -2.60360301e-01  -3.25740665e-01   2.44966179e-01   8.07715505e-02\n",
      "   1.16953218e+00  -8.97056758e-01  -2.72386789e-01  -8.33941102e-02\n",
      "  -1.32141984e+00  -9.77066934e-01  -1.27273750e+00  -3.48524332e-01\n",
      "  -1.08383143e+00  -1.42020071e+00  -8.32717836e-01  -5.30676067e-01\n",
      "  -2.60286499e-02  -3.37756872e-02  -4.75859255e-01  -2.89946273e-02\n",
      "   2.20363820e-03   2.84101702e-02   6.77693561e-02   1.16262794e-01\n",
      "   7.13630253e-03  -1.20983338e-02  -1.49468407e-01   1.44799636e-03\n",
      "  -1.53781287e-03   1.75991151e-02  -7.02554360e-02   9.85950753e-02\n",
      "  -3.72283310e-02   1.90018322e-02  -2.42904842e-01   3.53472680e-02\n",
      "   1.04729421e-02   6.30156649e-03  -9.09068510e-02   8.56361762e-02\n",
      "  -7.92960927e-05   6.69544423e-03   1.66168045e-02   7.03814551e-02\n",
      "  -1.13923894e-02   1.57915335e-02  -1.62527904e-01   4.17497493e-02\n",
      "  -8.84042773e-03  -2.28384361e-02  -1.27816379e-01   7.76060149e-02]\n"
     ]
    }
   ],
   "source": [
    "parameter_fire4 = reader.get_tensor(\"conv12/biases\")\n",
    "print(parameter_fire4.shape)\n",
    "print(parameter_fire4[:,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the values of the classification and the anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor number: 9\n",
      "Classes number: 3\n",
      "Classes number names ['car', 'pedestrian', 'cyclist']\n"
     ]
    }
   ],
   "source": [
    "print(\"Anchor number:\", mc.ANCHOR_PER_GRID)\n",
    "print(\"Classes number:\", mc.CLASSES)\n",
    "print(\"Classes number names\", mc.CLASS_NAMES)\n",
    "num_output = mc.ANCHOR_PER_GRID * (mc.CLASSES + 1 + 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detail of kitti function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os \n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "from dataset.imdb import imdb\n",
    "from utils.util import bbox_transform_inv, batch_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class kitti(imdb):\n",
    "    def __init__(self, image_set, data_path, mc):\n",
    "        imdb.__init__(self, 'kitti_'+image_set, mc)\n",
    "        self._image_set = image_set\n",
    "        self._data_root_path = data_path\n",
    "        self._image_path = os.path.join(self._data_root_path, 'training', 'image_2')\n",
    "        self._label_path = os.path.join(self._data_root_path, 'training', 'label_2')\n",
    "        self._classes = self.mc.CLASS_NAMES\n",
    "        self._class_to_idx = dict(zip(self.classes, xrange(self.num_classes)))\n",
    "        print(\"self.num_classes:\", self.num_classes)\n",
    "        print(\"self.classes:\", self.classes)\n",
    "        print(\"class to idx:\", self._class_to_idx)\n",
    "    \n",
    "        # a list of string indices of images in the directory\n",
    "        self._image_idx = self._load_image_set_idx() \n",
    "        print(\"image_class:\", self._image_idx)\n",
    "    # a dict of image_idx -> [[cx, cy, w, h, cls_idx]]. x,y,w,h are not divided by\n",
    "    # the image width and height\n",
    "        self._rois = self._load_kitti_annotation()\n",
    "\n",
    "    ## batch reader ##\n",
    "        self._perm_idx = None\n",
    "        self._cur_idx = 0\n",
    "    # TODO(bichen): add a random seed as parameter\n",
    "        self._shuffle_image_idx()\n",
    "        self._eval_tool = './dataset/kitti-eval/cpp/evaluate_object'\n",
    "        \n",
    "    def _load_image_set_idx(self):\n",
    "        image_set_file = os.path.join(\n",
    "            self._data_root_path, 'ImageSets', self._image_set+'.txt')\n",
    "        assert os.path.exists(image_set_file), \\\n",
    "            'File does not exist: {}'.format(image_set_file)\n",
    "\n",
    "        with open(image_set_file) as f:\n",
    "            image_idx = [x.strip() for x in f.readlines()]\n",
    "        return image_idx\n",
    "\n",
    "    def _image_path_at(self, idx):\n",
    "        image_path = os.path.join(self._image_path, idx+'.png')\n",
    "        assert os.path.exists(image_path), \\\n",
    "            'Image does not exist: {}'.format(image_path)\n",
    "        return image_path\n",
    "\n",
    "    def _load_kitti_annotation(self):\n",
    "        def _get_obj_level(obj):\n",
    "            height = float(obj[7]) - float(obj[5]) + 1\n",
    "            truncation = float(obj[1])\n",
    "            occlusion = float(obj[2])\n",
    "            if height >= 40 and truncation <= 0.15 and occlusion <= 0:\n",
    "                return 1\n",
    "            elif height >= 25 and truncation <= 0.3 and occlusion <= 1:\n",
    "                return 2\n",
    "            elif height >= 25 and truncation <= 0.5 and occlusion <= 2:\n",
    "                return 3\n",
    "            else:\n",
    "                return 4\n",
    "\n",
    "        idx2annotation = {}\n",
    "        for index in self._image_idx:\n",
    "            filename = os.path.join(self._label_path, index+'.txt')\n",
    "            with open(filename, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            f.close()\n",
    "            bboxes = []\n",
    "            for line in lines:\n",
    "                obj = line.strip().split(' ')\n",
    "                try:\n",
    "                    cls = self._class_to_idx[obj[0].lower().strip()]\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if self.mc.EXCLUDE_HARD_EXAMPLES and _get_obj_level(obj) > 3:\n",
    "                    continue\n",
    "                xmin = float(obj[4])\n",
    "                ymin = float(obj[5])\n",
    "                xmax = float(obj[6])\n",
    "                ymax = float(obj[7])\n",
    "                assert xmin >= 0.0 and xmin <= xmax, \\\n",
    "                   'Invalid bounding box x-coord xmin {} or xmax {} at {}.txt' \\\n",
    "                    .format(xmin, xmax, index)\n",
    "                assert ymin >= 0.0 and ymin <= ymax, \\\n",
    "                   'Invalid bounding box y-coord ymin {} or ymax {} at {}.txt' \\\n",
    "                    .format(ymin, ymax, index)\n",
    "                x, y, w, h = bbox_transform_inv([xmin, ymin, xmax, ymax])\n",
    "                bboxes.append([x, y, w, h, cls])\n",
    "\n",
    "            idx2annotation[index] = bboxes\n",
    "\n",
    "        return idx2annotation\n",
    "\n",
    "    def evaluate_detections(self, eval_dir, global_step, all_boxes):\n",
    "        \"\"\"Evaluate detection results.\n",
    "        Args:\n",
    "        eval_dir: directory to write evaluation logs\n",
    "        global_step: step of the checkpoint\n",
    "        all_boxes: all_boxes[cls][image] = N x 5 arrays of \n",
    "        [xmin, ymin, xmax, ymax, score]\n",
    "        Returns:\n",
    "        aps: array of average precisions.\n",
    "        names: class names corresponding to each ap\n",
    "        \"\"\"\n",
    "        det_file_dir = os.path.join(\n",
    "             eval_dir, 'detection_files_{:s}'.format(global_step), 'data')\n",
    "        if not os.path.isdir(det_file_dir):\n",
    "            os.makedirs(det_file_dir)\n",
    "\n",
    "        for im_idx, index in enumerate(self._image_idx):\n",
    "            filename = os.path.join(det_file_dir, index+'.txt')\n",
    "            with open(filename, 'wt') as f:\n",
    "                for cls_idx, cls in enumerate(self._classes):\n",
    "                    dets = all_boxes[cls_idx][im_idx]\n",
    "                    for k in xrange(len(dets)):\n",
    "                        f.write(\n",
    "                            '{:s} -1 -1 0.0 {:.2f} {:.2f} {:.2f} {:.2f} 0.0 0.0 0.0 0.0 0.0 '\n",
    "                            '0.0 0.0 {:.3f}\\n'.format(\n",
    "                                cls.lower(), dets[k][0], dets[k][1], dets[k][2], dets[k][3],\n",
    "                                dets[k][4])\n",
    "                        )\n",
    "\n",
    "        cmd = self._eval_tool + ' ' \\\n",
    "              + os.path.join(self._data_root_path, 'training') + ' ' \\\n",
    "              + os.path.join(self._data_root_path, 'ImageSets',\n",
    "                             self._image_set+'.txt') + ' ' \\\n",
    "              + os.path.dirname(det_file_dir) + ' ' + str(len(self._image_idx))\n",
    "\n",
    "        print('Running: {}'.format(cmd))\n",
    "        status = subprocess.call(cmd, shell=True)\n",
    "\n",
    "        aps = []\n",
    "        names = []\n",
    "        for cls in self._classes:\n",
    "            det_file_name = os.path.join(\n",
    "                os.path.dirname(det_file_dir), 'stats_{:s}_ap.txt'.format(cls))\n",
    "            if os.path.exists(det_file_name):\n",
    "                with open(det_file_name, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                assert len(lines) == 3, \\\n",
    "                   'Line number of {} should be 3'.format(det_file_name)\n",
    "\n",
    "                aps.append(float(lines[0].split('=')[1].strip()))\n",
    "                aps.append(float(lines[1].split('=')[1].strip()))\n",
    "                aps.append(float(lines[2].split('=')[1].strip()))\n",
    "            else:\n",
    "                aps.extend([0.0, 0.0, 0.0])\n",
    "\n",
    "            names.append(cls+'_easy')\n",
    "            names.append(cls+'_medium')\n",
    "            names.append(cls+'_hard')\n",
    "\n",
    "        return aps, names\n",
    "\n",
    "    def do_detection_analysis_in_eval(self, eval_dir, global_step):\n",
    "        det_file_dir = os.path.join(\n",
    "            eval_dir, 'detection_files_{:s}'.format(global_step), 'data')\n",
    "        det_error_dir = os.path.join(\n",
    "            eval_dir, 'detection_files_{:s}'.format(global_step),\n",
    "            'error_analysis')\n",
    "        if not os.path.exists(det_error_dir):\n",
    "            os.makedirs(det_error_dir)\n",
    "        det_error_file = os.path.join(det_error_dir, 'det_error_file.txt')\n",
    "\n",
    "        stats = self.analyze_detections(det_file_dir, det_error_file)\n",
    "        ims = self.visualize_detections(\n",
    "            image_dir=self._image_path,\n",
    "            image_format='.png',\n",
    "            det_error_file=det_error_file,\n",
    "            output_image_dir=det_error_dir,\n",
    "            num_det_per_type=10\n",
    "        )\n",
    "\n",
    "        return stats, ims\n",
    "\n",
    "    def analyze_detections(self, detection_file_dir, det_error_file):\n",
    "        def _save_detection(f, idx, error_type, det, score):\n",
    "            f.write(\n",
    "                '{:s} {:s} {:.1f} {:.1f} {:.1f} {:.1f} {:s} {:.3f}\\n'.format(\n",
    "                    idx, error_type,\n",
    "                    det[0]-det[2]/2., det[1]-det[3]/2.,\n",
    "                    det[0]+det[2]/2., det[1]+det[3]/2.,\n",
    "                    self._classes[int(det[4])], \n",
    "                    score\n",
    "                    )\n",
    "             )\n",
    "\n",
    "    # load detections\n",
    "        self._det_rois = {}\n",
    "        for idx in self._image_idx:\n",
    "            det_file_name = os.path.join(detection_file_dir, idx+'.txt')\n",
    "            with open(det_file_name) as f:\n",
    "                lines = f.readlines()\n",
    "            f.close()\n",
    "            bboxes = []\n",
    "            for line in lines:\n",
    "                obj = line.strip().split(' ')\n",
    "                cls = self._class_to_idx[obj[0].lower().strip()]\n",
    "                xmin = float(obj[4])\n",
    "                ymin = float(obj[5])\n",
    "                xmax = float(obj[6])\n",
    "                ymax = float(obj[7])\n",
    "                score = float(obj[-1])\n",
    "\n",
    "                x, y, w, h = bbox_transform_inv([xmin, ymin, xmax, ymax])\n",
    "                bboxes.append([x, y, w, h, cls, score])\n",
    "            bboxes.sort(key=lambda x: x[-1], reverse=True)\n",
    "            self._det_rois[idx] = bboxes\n",
    "\n",
    "    # do error analysis\n",
    "        num_objs = 0.\n",
    "        num_dets = 0.\n",
    "        num_correct = 0.\n",
    "        num_loc_error = 0.\n",
    "        num_cls_error = 0.\n",
    "        num_bg_error = 0.\n",
    "        num_repeated_error = 0.\n",
    "        num_detected_obj = 0.\n",
    "\n",
    "        with open(det_error_file, 'w') as f:\n",
    "            for idx in self._image_idx:\n",
    "                gt_bboxes = np.array(self._rois[idx])\n",
    "                num_objs += len(gt_bboxes)\n",
    "                detected = [False]*len(gt_bboxes)\n",
    "\n",
    "                det_bboxes = self._det_rois[idx]\n",
    "                if len(gt_bboxes) < 1:\n",
    "                    continue\n",
    "\n",
    "                for i, det in enumerate(det_bboxes):\n",
    "                    if i < len(gt_bboxes):\n",
    "                        num_dets += 1\n",
    "                    ious = batch_iou(gt_bboxes[:, :4], det[:4])\n",
    "                    max_iou = np.max(ious)\n",
    "                    gt_idx = np.argmax(ious)\n",
    "                    if max_iou > 0.1:\n",
    "                        if gt_bboxes[gt_idx, 4] == det[4]:\n",
    "                            if max_iou >= 0.5:\n",
    "                                if i < len(gt_bboxes):\n",
    "                                    if not detected[gt_idx]:\n",
    "                                        num_correct += 1\n",
    "                                        detected[gt_idx] = True\n",
    "                                    else:\n",
    "                                        num_repeated_error += 1\n",
    "                            else:\n",
    "                                if i < len(gt_bboxes):\n",
    "                                    num_loc_error += 1\n",
    "                                    _save_detection(f, idx, 'loc', det, det[5])\n",
    "                        else:\n",
    "                            if i < len(gt_bboxes):\n",
    "                                num_cls_error += 1\n",
    "                                _save_detection(f, idx, 'cls', det, det[5])\n",
    "                    else:\n",
    "                        if i < len(gt_bboxes):\n",
    "                            num_bg_error += 1\n",
    "                            _save_detection(f, idx, 'bg', det, det[5])\n",
    "\n",
    "                for i, gt in enumerate(gt_bboxes):\n",
    "                    if not detected[i]:\n",
    "                        _save_detection(f, idx, 'missed', gt, -1.0)\n",
    "                num_detected_obj += sum(detected)\n",
    "        f.close()\n",
    "\n",
    "        print ('Detection Analysis:')\n",
    "        print ('    Number of detections: {}'.format(num_dets))\n",
    "        print ('    Number of objects: {}'.format(num_objs))\n",
    "        print ('    Percentage of correct detections: {}'.format(\n",
    "            num_correct/num_dets))\n",
    "        print ('    Percentage of localization error: {}'.format(\n",
    "            num_loc_error/num_dets))\n",
    "        print ('    Percentage of classification error: {}'.format(\n",
    "            num_cls_error/num_dets))\n",
    "        print ('    Percentage of background error: {}'.format(\n",
    "            num_bg_error/num_dets))\n",
    "        print ('    Percentage of repeated detections: {}'.format(\n",
    "            num_repeated_error/num_dets))\n",
    "        print ('    Recall: {}'.format(\n",
    "            num_detected_obj/num_objs))\n",
    "\n",
    "        out = {}\n",
    "        out['num of detections'] = num_dets\n",
    "        out['num of objects'] = num_objs\n",
    "        out['% correct detections'] = num_correct/num_dets\n",
    "        out['% localization error'] = num_loc_error/num_dets\n",
    "        out['% classification error'] = num_cls_error/num_dets\n",
    "        out['% background error'] = num_bg_error/num_dets\n",
    "        out['% repeated error'] = num_repeated_error/num_dets\n",
    "        out['% recall'] = num_detected_obj/num_objs\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.num_classes: 3\n",
      "self.classes: ['car', 'pedestrian', 'cyclist']\n",
      "class to idx: {'cyclist': 2, 'car': 0, 'pedestrian': 1}\n",
      "image_class: ['000001', '000002', '000005', '000007', '000009', '000006', '000004', '000008', '000003', '000000']\n"
     ]
    }
   ],
   "source": [
    "imdb = kitti('train', '../data/KITTI', mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=orange > <font face=\"purisa\" size=8 color='0000ff'>\n",
    " Extended learning\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "<table><tr><td bgcolor=white > <font face=\"sawasdee\" size=6 color='0000ff'>\n",
    "range vs xrange\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "## For the most part, xrange and range are the exact same in terms of functionality. They both provide a way to generate a list of integers for you to use, however you please. The only difference is that range returns a Python list object and xrange returns an xrange object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: xrange(0, 10, 2)\n",
      "type of a: <type 'xrange'>\n",
      "member of a: a[0]= 0 a[1]= 2\n",
      "b: [0, 2, 4, 6, 8]\n",
      "type of b: <type 'list'>\n",
      "member of b: b[0]= 0 b[1]= 2\n",
      "c: [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "a = xrange(0,10,2)\n",
    "print(\"a:\", a)\n",
    "print(\"type of a:\", type(a))\n",
    "print(\"member of a:\", \"a[0]=\", a[0], \"a[1]=\", a[1])\n",
    "b = range(0,10,2)\n",
    "print(\"b:\", b)\n",
    "print(\"type of b:\", type(b))\n",
    "print(\"member of b:\",\"b[0]=\", b[0],\"b[1]=\", b[1])\n",
    "\n",
    "c = range(3)\n",
    "print(\"c:\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=orange > <font face=\"purisa\" size=8 color='0000ff'>\n",
    " Extended learning\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "<table><tr><td bgcolor=white > <font face=\"sawasdee\" size=6 color='0000ff'>\n",
    "zip\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "## zip takes n number of iterables and returns list of tuples. ith element of the tuple is created using the ith element from each of the iterables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd'), (5, 'e')]\n"
     ]
    }
   ],
   "source": [
    "list_a = [1, 2, 3, 4, 5]\n",
    "list_b = ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "zipped_list = zip(list_a, list_b)\n",
    "\n",
    "print (zipped_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鹅鹅鹅\n",
      "曲项向天歌\n",
      "锄禾日当午\n",
      "春种一粒粟\n",
      "0 鹅鹅鹅\n",
      "1 曲项向天歌\n",
      "2 锄禾日当午\n",
      "3 春种一粒粟\n"
     ]
    }
   ],
   "source": [
    "l = ['鹅鹅鹅', '曲项向天歌', '锄禾日当午', '春种一粒粟']\n",
    "\n",
    "for i in l:\n",
    "    print(i)\n",
    "\n",
    "# 可以获取下表，enumerate每次循环可以得到下表及元素\n",
    "for i, v in enumerate(l):\n",
    "    print(i, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a apple\n",
      "c car\n",
      "b banana\n",
      "d desk\n",
      "a apple\n",
      "c car\n",
      "b banana\n",
      "d desk\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
      "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "[2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "d = {'a':'apple', 'b':'banana', 'c':'car', 'd': 'desk'}\n",
    "\n",
    "for key in d:\n",
    "    # 遍历字典时遍历的是键\n",
    "    print(key, d.get(key))\n",
    "\n",
    "# for key, value in d.items():\n",
    "# 上下两种方式等价 d.items() <=> dict.items(d)\n",
    "for key, value in dict.items(d):\n",
    "    print(key, value)\n",
    "\n",
    "print([i for i in range(1, 11)])\n",
    "print([i*2 for i in range(1, 11)])\n",
    "print([i*i for i in range(1, 11)])\n",
    "print([str(i) for i in range(1, 11)])\n",
    "print([i for i in range(1, 11) if i % 2 == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=orange > <font face=\"purisa\" size=8 color='0000ff'>\n",
    " Extended learning\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "<table><tr><td bgcolor=white > <font face=\"sawasdee\" size=6 color='0000ff'>\n",
    "strip\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "## The strip() removes characters from both left and right based on the argument (a string specifying the set of characters to be removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xoxo love xoxo\n",
      "xoxo love xox\n",
      " xoxo love xoxo   \n",
      "droid is awesome\n"
     ]
    }
   ],
   "source": [
    "b = 'rabc\\t\\n'\n",
    "#print(b.strip()) # Remove '\\n', '\\r',  '\\t',  ' '\n",
    "print(b.strip('r'))\n",
    "string = ' xoxo love xoxo   '\n",
    "\n",
    "# Leading whitepsace are removed\n",
    "print(string.strip())\n",
    "\n",
    "print(string.strip(' o'))\n",
    "\n",
    "# Argument doesn't contain space\n",
    "# No characters are removed.\n",
    "print(string.strip('sti'))\n",
    "\n",
    "string = 'android is awesome'\n",
    "print(string.strip('an'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=orange > <font face=\"purisa\" size=8 color='0000ff'>\n",
    " Extended learning\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "<table><tr><td bgcolor=white > <font face=\"sawasdee\" size=6 color='0000ff'>\n",
    "lower\n",
    "</font></td></tr></table>\n",
    "<br>\n",
    "## The method lower() returns a copy of the string in which all case-based characters have been lowercased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
